"""
Emotion Recognition - Vision-Frame-Based Face Channel

__author__ = "Pablo Barros"

__version__ = "0.1"
__maintainer__ = "Pablo Barros"
__email__ = "barros@informatik.uni-hamburg.de"

More information about the implementation of the model:

Barros, P., Churamani, N., & Sciutti, A. (2020). The FaceChannel: A Light-weight Deep Neural Network for Facial Expression Recognition. arXiv preprint arXiv:2004.08195.

Barros, P., & Wermter, S. (2016). Developing crossmodal expression recognition based on a deep neural model. Adaptive behavior, 24(5), 373-396.
http://journals.sagepub.com/doi/full/10.1177/1059712316664017

"""

import cv2
from emotion_detection import EmotionDetection
import numpy

import tensorflow as tf
# config = tf.ConfigProto()
# config.gpu_options.allow_growth=True
# sess = tf.Session(config=config)
#
# finalImageSize = (1024,768) # Size of the final image generated by the demo
# categoricalInitialPosition = 460 # Initial position for adding the categorical graph in the final image
# faceSize = (64,64) # Input size for both models: categorical and dimensional
# faceDetectionMaximumFrequency = 20 # Frequency that a face will be detected: every X frames.
#
# affectiveMemory = AffectiveMemory.AffectiveMemory() # Affective Memory
#
# modelDimensional = modelLoader.modelLoader(modelDictionary.DimensionalModel)
#
# imageProcessing = imageProcessingUtil.imageProcessingUtil()
#
# GUIController = GUIController.GUIController()

cap = cv2.VideoCapture(0)
#cap.open(0)

if cap.isOpened():  # try to get the first frame
    rval, f = cap.read()
else:
    rval = False

emotion_detector = EmotionDetection()

while(True):
    # Capture frame-by-frame

        rval, frame = cap.read()

        valence, arousal = emotion_detector.get_arousal_valence_for_image(frame)


cap.release()
# cv2.destroyAllWindows()